{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_classification2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "flF93WzNQugt"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3H1aS5Q5zvC"
      },
      "source": [
        "!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmyir0xk6JVb"
      },
      "source": [
        "!unzip -qq cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1OteylJ9L-X"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuzYABnxy5Ix"
      },
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms \n",
        "from PIL import Image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIbn4Uuy6oXJ"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MeVa_ytzFQe"
      },
      "source": [
        "is_cuda = False\n",
        "if torch.cuda.is_available():\n",
        "    is_cuda = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UdkQoaeQP1N"
      },
      "source": [
        "파이토치 데이터셋 클래스 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2IywNREzG4_"
      },
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "class PyTorchCustomDataset(Dataset):\n",
        "    def __init__(self\n",
        "                 , root_dir = \"/content/cats_and_dogs_filtered/train\"\n",
        "                 , transform = None):\n",
        "        self.image_abs_path = root_dir\n",
        "        self.transform = transform\n",
        "        self.label_list = os.listdir(self.image_abs_path)\n",
        "        self.label_list.sort()\n",
        "        self.x_list = []\n",
        "        self.y_list = []\n",
        "        for label_index, label_str in enumerate(self.label_list):\n",
        "            img_path = os.path.join(self.image_abs_path, label_str)\n",
        "            img_list = os.listdir(img_path)\n",
        "            for img in img_list:\n",
        "                self.x_list.append(os.path.join(img_path, img))\n",
        "                self.y_list.append(label_index)\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.x_list[idx])\n",
        "        if image.mode is not \"RGB\":\n",
        "            image = image.convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, self.y_list[idx]\n",
        "\n",
        "    def __save_label_map__(self, dst_text_path = \"label_map.txt\"):\n",
        "        label_list = self.label_list\n",
        "        f = open(dst_text_path, 'w')\n",
        "        for i in range(len(label_list)):\n",
        "            f.write(label_list[i]+'\\n')\n",
        "        f.close()\n",
        "        pass\n",
        "\n",
        "    def __num_classes__(self):\n",
        "        return len(self.label_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbaH1tDdZik2"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8WF5tV1UKYj"
      },
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MODEL(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.network = models.resnet18(pretrained=True)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout()\n",
        "            , nn.Linear(1000, num_classes)\n",
        "            , nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.network(x)\n",
        "        return self.classifier(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rJpYqg6RXWz"
      },
      "source": [
        "main 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6fpTUpk_TKf"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "train_losses , train_accuracy = [],[]\n",
        "val_losses , val_accuracy = [],[] \n",
        "\n",
        "def main():\n",
        "    USE_CUDA = torch.cuda.is_available()\n",
        "    DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "    img_width, img_height = 224, 224\n",
        "    EPOCHS     = 10\n",
        "    BATCH_SIZE = 16\n",
        "    transform_train = transforms.Compose([\n",
        "                transforms.Resize(size=(img_width, img_height))\n",
        "                , transforms.RandomRotation(degrees=15)\n",
        "                , transforms.ToTensor()\n",
        "                ])\n",
        "    transform_test = transforms.Compose([\n",
        "                transforms.Resize(size=(img_width, img_height))\n",
        "                , transforms.ToTensor()\n",
        "                ])\n",
        "    TrainDataset = PyTorchCustomDataset\n",
        "    TestDataset = PyTorchCustomDataset\n",
        "    train_data = TrainDataset(root_dir = \"/content/cats_and_dogs_filtered/train\"\n",
        "                    , transform = transform_train)\n",
        "    test_data = TestDataset(root_dir = \"/content/cats_and_dogs_filtered/validation\"\n",
        "                    , transform = transform_test)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_data\n",
        "        , batch_size=BATCH_SIZE\n",
        "        , shuffle=True\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_data\n",
        "        , batch_size=BATCH_SIZE\n",
        "        , shuffle=True\n",
        "    )\n",
        "    train_data.__save_label_map__()\n",
        "    num_classes = train_data.__num_classes__()\n",
        "    model = MODEL(num_classes).to(DEVICE)\n",
        "    model_str = \"PyTorch_Classification_Model\"\n",
        "    model_str += \".pt\" \n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "    acc = 0.0\n",
        "   \n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        tr_loss = 0.0\n",
        "        tr_correct = 0.0       \n",
        "        for data, target in (train_loader):\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            tr_loss += F.nll_loss(output,target,reduction='sum').item()\n",
        "            pred = output.data.max(dim=1,keepdim=True)[1]\n",
        "            tr_correct += pred.eq(target.view_as(pred)).sum().item()          \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "        tr_ep_loss = tr_loss/len(train_loader.dataset)\n",
        "        tr_ep_accuracy = 100. * tr_correct/len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        te_loss = 0\n",
        "        te_correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in (test_loader):\n",
        "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "                output = model(data)\n",
        "                loss = F.cross_entropy(output, target)\n",
        "                te_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "                pred = output.max(1, keepdim=True)[1]\n",
        "                te_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        te_ep_loss = te_loss / len(test_loader.dataset)\n",
        "        te_ep_accuracy = 100. * te_correct / len(test_loader.dataset)\n",
        "        print('[{}] Train Loss: {:.4f}, Train Accuracy: {:.2f}% Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(\n",
        "                epoch, tr_ep_loss, tr_ep_accuracy, te_ep_loss, te_ep_accuracy))\n",
        "    \n",
        "        if acc < te_ep_accuracy:\n",
        "            acc = te_ep_accuracy\n",
        "            torch.save(model.state_dict(), model_str)\n",
        "            print(\"model saved!\")\n",
        "\n",
        "        train_losses.append(tr_ep_loss)\n",
        "        train_accuracy.append(tr_ep_accuracy)\n",
        "        val_losses.append(te_ep_loss)\n",
        "        val_accuracy.append(te_ep_accuracy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1GP1bNcB0Fv"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqbeFRs0kQSn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\n",
        "plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CjLOKvOkQzu"
      },
      "source": [
        "plt.plot(range(1,len(train_accuracy)+1),train_accuracy,'bo',label = 'train accuracy')\n",
        "plt.plot(range(1,len(val_accuracy)+1),val_accuracy,'r',label = 'val accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o11JiSB2DcPQ"
      },
      "source": [
        "가중치파일(PyTorch_Classification_Model.pt) \n",
        "과 “pytorch_network_model.py” 파일, “label_map.txt.”파일을 colab에 업로드합니다.\n",
        "\n"
      ]
    }
  ]
}